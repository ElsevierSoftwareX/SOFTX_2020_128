\section{The algorithm} \label{sec:algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  OVERVIEW
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Overview} \label{sec:algorithm:overview}
The Omicron algorithm is developed in C++ and the code lives in the Virgo software repository~\cite{VirgoSVN}. Omicron is built upon GWOLLUM~\cite{GWOLLUM} libraries used to perform every step of an Omicron analysis. The GWOLLUM package depends on external libraries. The FrameL~\cite{FrameL} library is used to perform IO operations on data frame files~\footnote{The frame format was developed for interferometric gravitational-wave detectors' data.}. Mathematical routines developed in the GNU Scientific Library~\cite{GSL} are commonly used by GWOLLUM functions. Discrete Fourier transforms are performed using the FFTW~\cite{FFTW} algorithm. Finally, the GWOLLUM and Omicron codes deeply rely on C++ classes developed in the CERN ROOT~\cite{Brun:1997pa} framework. For example, ROOT classes are used for plotting purposes, for event storage or for data access. To deal with package dependencies, the CMT~\cite{CMT} configuration management tool was chosen.

A fully object-oriented framework is adopted when developing GWOLLUM and Omicron, in which C++ classes and inheritance features are extensively used. The Omicron algorithm is entirely based on the \texttt{Omicron} C++ class which member functions are used to perform the analysis steps. A typical Omicron application is represented by the sequence of functions represented in Fig.~\ref{fig:omicron_flowchart}. The \texttt{Omicron} constructor must be called first, using an input option file listing all the parameters defining the search one wants to perform. Then, the \texttt{Omicron} object must be provided with time segments to process. This is done with the \texttt{Omicron::InitSegment()} function. These time segments are processed sequentially with the \texttt{Omicron::NewChunk()} function. For every time chunk, the list of channels to process is looped over with the \texttt{Omicron::NewChannel()} function. The input data vector is loaded with the \texttt{Omicron::LoadData()} function. The data is then conditioned; it is downsampled to a working frequency. This is performed with the  \texttt{Omicron::Condition()} function. Before applying the $Q$ transform, the data is whitened by normalizing the data spectrum by the noise power spectrum density. The whitened data is finally projected onto a basis of windowed complex exponentials, as described in Sec.~\ref{sec:method}. This is done using the \texttt{Omicron::Project()} function. When calling the \texttt{Omicron::WriteOutput()} function, the Omicron data products are saved to disk~\footnote{The html report is saved when calling the \texttt{Omicron} destructor.}.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/omicron_flowchart.eps}
  \caption{Standard \texttt{Omicron} analysis flowchart. The standard sequence of class functions is presented. Loops must be performed over data chunks and channels. They are represented by the dashed-line rectangles.}
  \label{fig:omicron_flowchart}
\end{figure}

This sequence of actions is performed by the \texttt{omicron.exe} executable. This programs runs the Omicron analysis using a list of arguments:
\begin{itemize}
  \item \texttt{omicron.exe gps\_start gps\_stop /path/to/parameters.file}. The Omicron algorithm is run over a single time segment starting at GPS time \texttt{gps\_start} and stopping at GPS time \texttt{gps\_end} and using the parameters listed in the file \texttt{/path/to/parameters.file}.
  \item \texttt{omicron.exe /path/to/segments.file /path/to/parameters.file}. The Omicron algorithm is run over all the time segments listed in \texttt{/path/to/segments.file} and using the parameters listed in the file\\
    \texttt{/path/to/parameters.file}.
  \item \texttt{omicron.exe gps\_center /path/to/parameters.file}. The Omicron algorithm is run over a single time chunk centered on GPS time \texttt{gps\_center} and using the parameters listed in the file \texttt{/path/to/parameters.file}.
\end{itemize}
In Appx~\ref{appx:parameters}, an example of a parameter file is given. Omicron parameters are specified using a sequence of two string keywords.

The \texttt{Omicron} class offers additional methods which can be used to tailor specfic applications (see, for example, Sec.~\ref{sec:algorithm:online}). For an up-to-date and extensive description of these methods, refer to the doxygen documentation~\cite{Omicron_doxygen}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  DISCRETE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The discrete analysis} \label{sec:algorithm:discrete}

The Omicron algorithm is designed to process any data time series $x(t)$ associated to a gravitational-wave detector channel, e.g. the detector output channel, an environmental sensor, a photodiode signal, etc. The data consists of a discrete time sequence, $x[j]$, which is identified by a channel name and a native sampling frequency, $f_s$, defining the time separation between two consecutive data points $\delta t = t_{j+1}-t_j = 1/f_s$. As we will see in Sec.~\ref{sec:algorithm:conditioning}, the Omicron algorithm includes a data conditioning step where the input data is downsampled to a working sampling frequency $f_w$, allowing for an optimized subsequent processing. The data is then iteratively analyzed by time chunks of fixed duration $T_c$, corresponding to $N_c=T_cf_w$ data samples.

As presented in Sec.~\ref{sec:method}, the Omicron analysis requires to perform multiple Fourier transforms. The forward and inverse Fourier transforms of Eq.~\ref{eq:FTforward} and~\ref{eq:FTbackward} are discretized as 
\begin{equation}
  \tilde{x}[k]=\frac{1}{f_w}\sum_{j=0}^{N_c-1}{x[j]\mathrm{e}^{-2i\pi jk/N_c}}
  \label{eq:dFTforward}
\end{equation}
and
\begin{equation}
  x[j]=\frac{f_w}{N_c}\sum_{k=0}^{N_c-1}{\tilde{x}[k]\mathrm{e}^{+2i\pi jk/N_c}}.
  \label{eq:dFTbackward}
\end{equation}
The frequency-domain data vector, $\tilde{x}$, is of size $N_c$ and the frequency sample interval is $\delta f = f_{k+1}-f_k = f_w/N_c = 1/T_c$. By convention, the first element, $\tilde{x}[0]$ is the DC component which is a purely real number. Positive frequencies are stored in the first half of $\tilde{x}$: $f_k=kf_w/N_c$, with $1\le k \le N_c/2$. The element $\tilde{x}[N_c/2]$ is purely real and is associated to the Nyquist frequency $f_{\text{Nyquist}}=f_w/2$. Negative frequencies are stored backward in the second half of $\tilde{x}$: $f_k=(k-N_c)f_w/N_c$, with $N_c/2 < k < N_c$.

Discrete Fourier transforms are performed with the FFTW~\cite{FFTW} algorithm. They can be computationally expensive and care must be taken to optimize the use of FFTW routines.

A first approach is to only work with vector sizes which are a power of two. With such a configuration, the FFTW routines provide optimal performance. With Omicron, the working sampling frequency $f_w$ and the chunk duration $T_c$ are required to each be a power of two. Therefore $N_c$ is a power of two.

Another possibility of optimization is to take advantage from the fact that, most often, we work with purely real data vectors. For instance, the detector signal $x[j]$ is a purely real time series. The Fourier transform $x\rightarrow\tilde{x}$ is a real-to-complex transform. As a result, the spectrum, $\tilde{x}[k]$, is symmetrical around DC. The negative frequencies are ignored and only one-sided data vectors are considered: $\tilde{x}$ is of size $N_c/2+1$. This redundancy is exploited by the FFTW algorithm to reduce the computing cost, both memory and speed.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  TILING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Tiling the parameter space} \label{sec:algorithm:tiling}

When the \texttt{Omicron} constructor is called, the tiling structure described in Sec.~\ref{sec:method:tiles} is created using the parameters listed in the user option file. The targeted parameter space must be specified: the $Q$ range, $[Q_{min}; Q_{max}]$, the frequency range, $[\phi_{min}; \phi_{max}]$ and a time range. The time range is fixed to the characteristic chunk duration, $T_c$, and is centered on 0: $[-T_c/2; +T_c/2]$. If necessary, the $Q_{min}$ and $\phi_{max}$ parameters are automatically adjusted so that they verify the anti-aliasing conditions of Eq.~\ref{eq:antialias1} and Eq.~\ref{eq:antialias2}. In addition, it is required to work with an integrated mismatch distance along the time dimension $s_\tau\ge4$, which translates into a minimum permissible frequency, $\phi_{min} \ge 2Q/(\pi T_c)$.
The user options must also include the maximum fractional energy loss due mismatch, $\mu_{max}$, from which the number of tiles used to cover the parameter space is determined.

A $Q$ plane object is implemented as a C++ class inheriting from the 2-D histogram class of ROOT (\texttt{TH2D}). The number of $Q$ planes, $N_Q$, is equal to the next integer verifying condition of Eq.~\ref{eq:tiledistanceq}. The $Q$ planes, indexed by $q$, are given a $Q$ value obtained from Eq.~\ref{eq:q}.

A $Q$ plane histogram is then vertically binned into logarithmically-spaced frequency rows. The number of frequency rows, $N_\phi(Q_q)$, is equal to the next integer verifying condition of Eq.~\ref{eq:tiledistancephi}. For each frequency row $(q,l)$, the horizontal time axis is divided into $N_\tau(Q_q,\phi_{ql})$ linear bins, $N_\tau(Q_q,\phi_{ql})$ being the next power of two verifying the condition of Eq.~\ref{eq:tiledistancetau}. Indeed, in Sec.~\ref{sec:algorithm:discrete}, we explained that working with power-of-two vector sizes is computationally more efficient when performing Fourier transforms. The tile time and frequency, $(\tau_{qlm}, \phi_{ql})$, is given by the histogram bin center obtained from~Eq.\ref{eq:tau} and Eq.~\ref{eq:phi}. It is also useful to give the histogram bin width in both the time and frequency dimensions:
\begin{align}
  \Delta\tau_{ql} &= T_c / N_\tau(Q_q, \phi_{ql}), \label{eq:dtau} \\
  \Delta\phi_{ql} &= 4\phi_{ql}\sqrt{\frac{\mu_{max}}{3(2+Q_q^2)}}.\label{eq:dphi}
\end{align}

A realistic example of a tiling structure is represented in Fig.~\ref{fig:tiling}, using the parameters listed in Appx~\ref{appx:parameters}. With this setting, 5 $Q$ planes are generated, representing a total of 2,742,016 tiles over a chunk of $T_c=64$~s and between $\phi_{min}=20$~Hz and $\phi_{max}=500$~Hz. For the plane with the lowest-$Q$ value, the time resolution varies between 0.49~ms and 15.63~ms and the frequency resolution spans from 4.5~Hz to 91.1~Hz. For the highest-$Q$ plane, the time resolution varies between 7.81~ms and 250.00~ms and the frequency resolution spans from 0.3~Hz to 7.2~Hz.
\begin{figure}
  \center
  \epsfig{width=7.5cm, file=./figures/q0.eps} \epsfig{width=7.5cm, file=./figures/q1.eps} \\
  \epsfig{width=7.5cm, file=./figures/q2.eps} \epsfig{width=7.5cm, file=./figures/q3.eps} \\
  \epsfig{width=7.5cm, file=./figures/q4.eps}
  \caption{Example of a realistic tiling structure using the parameters given in Appx~\ref{appx:parameters}. When requiring a maximal energy loss of $\mu_{max}=20\%$, 5 $Q$ planes are needed to cover the $Q$ range $[\sqrt{11}; 100]$. Each $Q$ plane is then tiled (black and green rectangles) along frequency rows delimited by the red dashed lines. To distinguish the tiles, the time chunk is zoomed in $\pm 100$~ms.}
  \label{fig:tiling}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Windows
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The windows} \label{sec:algorithm:window}
As presented in Eq.~\ref{eq:qtransform2}, the $Q$ transform includes windowing the data in the frequency domain. In Sec.~\ref{sec:method:window}, we discussed the possibility of using a bisquare window to approximate the ideal Gaussian window. Such a bisquare window is generated for each frequency row $l$ of each $Q$ plane $q$ composing the tiling structure presented in Sec.~\ref{sec:algorithm:tiling}. The window expression, given in Eq.~\ref{eq:bisquare}, must be discretized using the conventions defined in Sec.~\ref{sec:algorithm:discrete}:
\begin{equation}
  \tilde{w}_{ql}[k] = \tilde{w}_{ql}^*[k] =
  \begin{cases}
    W_b \left[1 - \left(\frac{2k}{M_{ql}-1}\right)^2 \right]^2 & 0\le k < \frac{M_{ql}+1}{2}, \\
    W_b \left[1 - \left(\frac{2(k-N_c)}{M_{ql}-1}\right)^2 \right]^2 & N_c-\frac{M_{ql}-1}{2}\le k < N_c, \\
    0 & \textrm{otherwise},
  \end{cases}
  \label{eq:dbisquare1}
\end{equation}
where $M_{ql}=2\lfloor \delta f(\phi_{ql},Q_q) T_c \rfloor + 1$ is the window size, obtained using the relation $\delta f(\phi_{ql},Q_q) = \phi_{ql}\sqrt{11}/Q_q$. The window vector $\tilde{w}$ is computed and saved for each $Q$ plane $q$ and each frequency row $l$. To limit the memory usage, the 0 values are not saved and
\begin{equation}
  \tilde{w}_{ql}[k] = \tilde{w}_{ql}^*[k] =
  \begin{cases}
    W_b \left[1 - \left(\frac{2k}{M_{ql}-1}\right)^2 \right]^2 & 0\le k < \frac{M_{ql}+1}{2}, \\
    W_b \left[1 - \left(\frac{2(k-M_{ql})}{M_{ql}-1}\right)^2 \right]^2 & \frac{M_{ql}+1}{2}\le k < M_{ql}.
  \end{cases}
  \label{eq:dbisquare2}
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  DATA ACCESS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The data access} \label{sec:algorithm:data}
The input data time series is read using the FrameL~\cite{FrameL} library, developed to perform read/write file operations using the Frame format~\footnote{The frame format is a data format specifically developed for interferometric gravitational-wave detectors.}. The data must be provided through a Frame File List (FFL) file which consists in an ASCII file with the file extension ``.ffl''. This file must contain a list of frame files described over five columns: the path to the frame file, the GPS information for the file start, the file duration in seconds, the GPS time of the first event and the GPS time of the last event~\footnote{A FFL file can be obtained using the FrameL program \texttt{FrDump.exe}: \texttt{FrDump.exe -i /path/to/frame/files/*.gwf -d 0 $>$ fflfile.ffl}}. The GWOLLUM class, \texttt{ffl}, is designed to offer an improved C++ interface to access frame data. For example, the \texttt{ffl} class provides compatibility with the specific LIGO lal-cache file format.

The data is loaded by time chunks. The chunk is an important charactistic time scale which is user-defined in the parameter file. It defines the time sequence adopted to analyze the data. The chunk duration, $T_c$, directly determines the size of Omicron data containers: $N_c=f_wT_c$.

Fig.~\ref{fig:segmentation} presents how the input data is segmented and analyzed. The input time segments, provided by the Omicron command line, are subdivided into chunks. The size of the chunks is fixed and is defined in the user parameter file. Chunks overlap by a fixed amount of time. The overlap duration, $T_o$, is also set in the user parameter file. The segment size does not generally matches the chunk and overlap structure. As a result, for the last chunk of a segment, the overlap is adjusted to match the current segment end. The overlapping structure is introduced to manage edge artifacts due to the forward and backward filtering of the data (see Sec.~\ref{sec:algorithm:conditioning}). Some data is irremediably lost in this process: segments shorter than the chunk duration cannot be analyzed and the first and last edges of a segment (half the overlap) are not saved.
\begin{figure}
  \center
  \epsfig{width=15cm, file=./figures/segmentation.eps}
  \caption{Data segmentation. The input segments are analyzed sequentially, chunk by chunk. The chunks, represented by the red lines, have a fixed size and are defined in the user parameter file. Two consecutive chunks overlap by a fixed amount of time, also defined in the parameter file. The overlap for the last chunk of a segment is modified to adjust the segment size. Only the central part of the chunk, represented by the black lines, is meaningful. Only Omicron triggers in this central region are saved.}
  \label{fig:segmentation}
\end{figure}

The chunk and overlap structure must verify some conditions:
\begin{enumerate}
\item The durations must be integer values. Omicron only supports integer durations.
\item The chunk duration must be a power of 2 value and longer than or equal to 4 seconds.
\item The overlap duration must be an even value and shorter than the chunk duration for obvious reasons.
\end{enumerate}

Chunks and channels are internally looped over using the \texttt{Omicron::NewChunk()} and \texttt{Omicron::NewChannel()} functions. For a given chunk and a given channel, a data vector is filled with the raw time series, using the \texttt{Omicron::LoadData()} function. The native sampling frequency for the channel data stream, $f_s$, is directly determined by the size of the vector which is loaded. This is checked for every chunk. This way, a change of the channel native sampling frequency is automatically accounted for when looping over the chunks.

Omicron offers the possibility to inject simulated signals on top of the channel data time series. Such injections are perfomed by the \texttt{Omicron::LoadData()} function, just after the data vector is loaded. Injected signals are parameterized in various ways which will be described in Sec.~\ref{sec:algorithm:injections}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  DATA CONDITIONING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The data conditioning} \label{sec:algorithm:conditioning}
The chunk data vector is transformed to optimize the performance of the subsequent processing. First, the signal DC component is set to 0. This is required to limit edge artifacts when filtering the data. The signal is then downsampled to a lower working frequency, $f_w$, to maximize the processing speed and lower the memory usage. The filtering C++ code is inspired from the routines developed in the LSC Algorithm Library Suite~\cite{LALSUITE}. To avoid aliasing, a 20$^{\mathrm{th}}$-order Butterworth low-pass filter with an attenuation factor of 0.1 is applied using a cutoff frequency set at the targeted Nyquist frequency, $f_w/2$. The filter is applied in the time domain first forwards and then backwards in order to cancel the phase delay introduced by a single pass. The disadvantage of the Butterworth filter is that, since it is an IIR filter, it is not possible to determine the exact length of corrupted data at the start and end of the output time series. The chunk overlap duration (see Sec.~\ref{sec:algorithm:data}) must be chosen with care to reject these filtering artifacts. Finally, the time-series is decimated to the desired working sampling frequency. The resulting working data vector size is now reduced to $N_c=f_w \times T_c$.

Optionally, it is possible to high-pass filter the data to reduce the signal dynamic range or, simply, to remove some low-frequency content. The working vector is high-pass filtered using a 12$^{\mathrm{th}}$-order Butterworth filter. This is done with zero phase distortion by first forward filtering and then reverse filtering the working vector. Once again, the chunk overlap duration must be long enough to remove the filtering artifacts. The filter frequency cutoff must be defined by the user in the parameter file.

The final step of the conditioning process consists of applying a Tukey window to the time-series, offering a smooth transition to 0 at both chunk ends. The expression of the Tukey window implemented in \texttt{Omicron} is:
\begin{equation}
  w_{\mathrm{tukey}}(t) = 
  \begin{cases}
     \frac{1}{2}\left[ 1+\cos{\left(2\pi\frac{t}{T_o}-\pi\right)}\right]& t < T_o/2, \\
     \frac{1}{2}\left[ 1+\cos{\left(2\pi\frac{(t-T_c)}{T_o}+\pi\right)}\right]& t > T_c-T_o/2, \\
     1.0 & \mathrm{otherwise}.
  \end{cases}
\end{equation}
Fig.~\ref{fig:tukey} presents examples of Tukey windows using several overlap durations.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/tukey.eps}
  \caption{Tukey windows used to smoothly transition the data time series to 0. A cosine function is applied at both chunk ends over half the overlap duration. Here, we used $T_c=64$~s and $T_o = 4$, 8, 16 and 32 s.}
  \label{fig:tukey}
\end{figure}

The conditioning of the data is illustrated in Fig.~\ref{fig:conditioning}. Omicron is run using the parameter file given in Appx.~\ref{appx:parameters}. The input data is originally sampled at 16384~Hz, the spectrum of which is represented in black in the upper plot. First, it is downsampled at a working frequency of 2048~Hz. The resulting spectrum is represented in blue and ends at the Nyquist frequency of 1024~Hz. After the high-pass filter, frequencies below 20~Hz are attenuated as shown by the red spectrum. The ratio of spectra of the different filtering steps are plotted in the middle and at the bottom of Fig.~\ref{fig:conditioning}.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/conditioning.eps}
  \caption{The upper plot displays the noise data spectra measured at different steps of the conditioning process. The black curve presents the spectrum of the raw data between 1~Hz and the Nyquist frequency of 8192~Hz. The raw data are downsampled to a working frequency $f_w=2048$~Hz. The resulting spectrum is represented in blue. The downsampled data is then high-pass filtered ($f>20$~Hz) and the measured spectrum is represented in red. The ratio between the downsampled and the raw spectrum is plotted in the middle. The lower plot shows the ratio between the high-passed and the downsampled spectra.}
  \label{fig:conditioning}
\end{figure}

The data conditioning is performed using the \texttt{Condition()} function of the \texttt{Omicron} class.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  DATA WHITENING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The data whitening} \label{sec:algorithm:whitening}

As described in Sec.~\ref{sec:method:whitening}, the $Q$ transform is applied to whitened data. The conditioned chunk data vector elements are re-weighted using the noise one-sided power spectral density. The noise PSD is estimated using the method developed for the \texttt{FINDCHIRP} algorithm~\cite{Allen:2005fk}. This method, inspired from the Welch method~\cite{Welch:1967}, offers a reliable and robust PSD estimate for non-Gaussian data.

A time-domain data vector $d$ of duration $T_\mathrm{PSD}$ and sampled at the Omicron working frequency $f_w$ is divided into sub-vectors $d_s$. These sub-segments of duration $T_\mathrm{spec}$, are indexed by $s$ and overlap by 50\%, as represented at the top of Fig.~\ref{fig:psdseg}. The one-sided periodograms, defined in Eq.~\ref{eq:periodogram}, are computed for all sub-segments using $f_wT_\mathrm{spec}$ data points and a normalized~\footnote{the window is normalized such that $\sum_{j=0}^{f_wT_\mathrm{spec}-1}{w_H^2[i]} = f_wT_\mathrm{spec}$} Hann window, $w_H$:
\begin{align}
  P_s[k] &= \frac{2}{T_\mathrm{spec}}\left|\widetilde{(w_Hd_s)}[k]\right|^2 \\
  &= \frac{2}{T_\mathrm{spec}f_w^2}\left|\sum_{j=0}^{f_wT_\mathrm{spec}-1}{d_s[j]w_H[j]e^{-2i\pi jk/(f_wT_{spec})}}\right|^2.
\end{align}

To work with independent random quantities, the sub-segments are separated into two sets of non-overlapping segments: $N^e$ sub-segments with even indexes and $N^o$ sub-segments with odd indexes. Instead of using a mean, as prescribed with the traditional Welch method, we use a median which offers a more robust estimator for the power spectrum. However, as explained in \cite{Allen:2005fk}, for Gaussian noise, the resulting median value must be corrected by a bias factor, $\alpha(N)=\sum_{n=0}^{N-1}{(-1)^{n+1}/n}$, to recover an estimate using a mean value: $S_n^e[k]=\mathrm{median}(P_0[k], P_2[k],\dots)/\alpha(N^e)$ and $S_n^o[k]=\mathrm{median}(P_1[k], P_3[k],\dots)/\alpha(N^o)$. The final PSD is obtained by taking the mean of even and odd PSDs: $S_n[k]=(N^eS_n^e[k]+N^oS_n^o[k])/(N^e+N^o)$. This procedure to estimate the PSD is illustrated in Fig.~\ref{fig:psdseg}.
\begin{figure}
  \center
  \epsfig{width=15cm, file=./figures/psdseg.eps} \\
  \epsfig{width=8cm, file=./figures/psd_even.eps}
  \epsfig{width=8cm, file=./figures/psd_odd.eps}
  \caption{The top panel presents the data segmentation used to estimate the noise power spectral density. The data segment of duration $T_\mathrm{PSD}$ is divided into two sets of non-overlapping sub-segments of duration $T_\mathrm{spec}$: the ``odd'' and ``even'' sets. The odd sub-segments are shifted by $T_\mathrm{spec}/2$ with respect to the even sub-segments. Note that a small time segment at the end of the data segment may be left unused. The power spectral density is estimated for even sub-segments (bottom-left panel) and for odd subsegments (bottom-right pannel). The individual periodograms are displayed with dimmed lines while the resulting median PSD is plotted with a thick line. The odd and even PSDs are averaged into the final PSD. This example was obtained using the Omicron configuration given in Appx.~\ref{appx:parameters}: 150 even subsegments and 149 odd sub-segments were used to cover an input data vector of duration $T_\mathrm{PSD}=300$~s.}
  \label{fig:psdseg}
\end{figure}

For Omicron, the time scale to estimate the PSD is decoupled from the chunk structure; $T_\mathrm{PSD}$ can be set independently from the $T_c$ parameter, using the option file. When a new data chunk is loaded, the data vector, excluding half the overlap on both chunk edges, is used to compute new periodograms as described above. These periodograms are saved in a circular buffer of duration $T_\mathrm{PSD}$. For each chunk, the PSD is then estimated using the data available in the buffer. If the buffer is longer than one chunk, \textit{i.e.} $T_\mathrm{PSD} > T_c-T_o$, the PSD is not optimally estimated for the first chunks as the circular buffer is not full. Using $T_\mathrm{PSD} \le T_c-T_o$ is equivalent to a situation where $T_\mathrm{PSD} = T_c-T_o$, meaning that the chunk is self-whitened. The PSD circular buffer is flushed whenever a new analysis time segment starts (the time segments are described in Sec.~\ref{sec:algorithm:data}). 

The PSD frequency resolution must be compatible with the Omicron tiling structure described in Sec.~\ref{sec:algorithm:tiling} and be high enough to resolve all the $Q$ plane frequency rows. The PSD resolution is set by the hard-coded parameter $T_\mathrm{spec}$. If the search frequency range, $[\phi_{min}; \phi_{max}]$, is such that $\phi_{min}>1$~Hz, $T_\mathrm{spec}=2$~s. The PSD frequency resolution is then fixed at $1/T_\mathrm{spec}=0.5$~Hz. If the search frequency range goes below 1~Hz, $T_\mathrm{spec}$ is adjusted such that the number of points in the spectrum is the next power of two above $2f_w/\phi_{min}$.

Before projecting the data onto the tiling structure, the data chunk, $x$, is Fourier-transformed and whitened as presented in Eq.~\ref{eq:whitening}. However, the noise PSD, $S_n$, and the data vector, $\tilde{x}$, do not have the same frequency resolution; by construction, the PSD resolution is lower than the data resolution.  To re-weight the data sample $\tilde{x}[k]$, a linear interpolation is used to estimate the PSD value at the frequency $k/T_c$.

Finally, as suggested in Sec.~\ref{sec:algorithm:discrete}, to optimize the processing, real-to-complex Fourier transforms are performed to compute both the periodograms, $P_s$, and the frequency-domain chunk data vector, $\tilde{x}$. The whitened frequency-domain vector elements are simply given by
\begin{equation}
  \tilde{x}^{wh}[k] = \frac{\tilde{x}[k]}{\sqrt{S_n(k/T_c)/2}}, \qquad 0 \le k \le \frac{N_c}{2},
  \label{eq:white_simple}
\end{equation}
where $S_n(k/T_c)$ is the PSD value intrapolated at the frequency $k/T_c$.

Fig.~\ref{fig:white} illustrates the effect of the whitening method. A PSD is estimated using 300 s of data and is used to whiten one data chunk of 64 s. The plots in Fig.\ref{fig:white} show the PSD of the chunk before and after whitening. As expected, the PSD of the whitened data is flat and equal to 2. We note that, powerful spectral lines tend to be over-whitened. This effect is due to the low PSD frequency resolution and the linear interpolation which is performed to match the chunk frequency resolution: on both sides of a narrow line, the PSD is over-estimated. This effect will be studied in greater detcails in Sec.~\ref{sec:characterization:whitening}.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/white1.eps} \\
  \epsfig{width=10cm, file=./figures/white2.eps}
  \caption{Power spectral density of a data chunk before (top) and after (bottom) applying the whitening procedure.}
  \label{fig:white}
\end{figure}


The number of points in the PSD is kept small to guarantee an optimized processing: fast Fourier transforms and low memory usage. However, a low frequency resolution can sometimes be an issue for the FFTW algorithm: the frequency resolution is not high enough to account for large variations in the spectrum (especially at low frequencies). For this reason, the noise PSD is estimated into 2 steps. A first PSD estimate is computed as descibed above: $S_{n,1}$. It is used to perform a first whitening as prescribed by Eq.~\ref{eq:white_simple}. We obtain a whitened data vector $\tilde{x}_1^{wh}$. A Fourier transform is applied to switch back to the time domain: $x_1^{wh}$. Then, a second whitening procedure is applied: the data vector $x_1^{wh}$ is used to compute a second PSD, $S_{n,2}$, using the method presented above. The data vector is whitened a second time using the second PSD estimate $S_{n,2}$. Instead of Eq.~\ref{eq:white_simple}, the double whitening procedure implemented in Omicron is equivalent to:
\begin{equation}
  \tilde{x}^{wh}[k] = \frac{\tilde{x}[k]}{\sqrt{\frac{S_{n,1}(k/T_c)}{2}\frac{S_{n,2}(k/T_c)}{2}}}, \qquad 0 \le k \le \frac{N_c}{2}.
  \label{eq:white_double}
\end{equation}
When comparing Eq.~\ref{eq:white_simple} and Eq.~\ref{eq:white_double}, it is clear that the final noise PSD is given by
\begin{equation}
  S_n = \frac{S_{n,1}S_{n,2}}{2}.
\end{equation}
Fig.~\ref{fig:doublewhite} illustrates why, in some cases, the double whitening procedure is mandatory to obtain a correct PSD estimate. In this example, we used a signal with a large dynamic range at low frequency. The plot at the top of Fig.~\ref{fig:doublewhite} shows the two PSDs, $S_{n,1}$ (blue curve) and $S_{n,2}$ (green curve), used to compute the final PSD $S_n$ (red curve). The first estimate, $S_{n,1}$, is correct above $f\sim 70$~Hz while it presents large deviations from the true PSD for $f<70$~Hz. The FFTW algorithm is not able to manage such a large dynamic range with a low frequency resolution. The second PSD, $S_{n,2}$, is used to correct this bias and to obtain a correct PSD estimate $S_n$. As expected it is flat and equal to 2 for $f>70$~Hz and it deviates from 2 below 70~Hz. To check that the double whitening procedure provides a correct PSD estimate, we compute a single PSD with a higher frequency resolution. The resulting PSD is plotted at the bottom of Fig.~\ref{fig:doublewhite}, in black. It is well matched by the low-resolution PSD estimated with the double-whitening method.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/psd_double.eps} \\
  \epsfig{width=10cm, file=./figures/psd_hdld.eps}
  \caption{Double whitening procedure. The top plot presents the two steps leading to the final PSD estimate. The first PSD estimate, $S_{n,1}$, is represented by the blue curve. The frequency resolution is too low to resolve the large dynamic range at low frequency. Therefore the first estimate is biased. The data are whitened using this first estimate, reducing the dynamic range. Then the PSD is estimated a second time, $S_{n,2}$, and is represented by the green curve. It is used to correct the first estimate. The final PSD estimate is given by $S_n=S_{n,1}S_{n,2}/2$ and is represented in red. The bottom panel compares this final PSD estimate (in red) with what is obtained with a single estimate using a high frequency resolution.}
  \label{fig:doublewhite}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  DATA PROJECTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The data projection} \label{sec:algorithm:projection}

The whitened frequency-domain chunk data vector $\tilde{x}$ (in this section, for brevity, we drop the $wh$ superscript) is applied the $Q$ transform of Eq.~\ref{eq:qtransform2} for each tile $(m, l, q)$. In a discrete framework, Eq.~\ref{eq:qtransform2} writes
\begin{equation}
  X(j,l,q)=\frac{f_w}{N_c}\sum_{k=0}^{N_c-1}{\tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{+2i\pi jk/N_c}},
  \label{eq:dqtransform1}
\end{equation}
where $p_{ql}=\lfloor \phi_{ql}T_c \rfloor$ is the number of frequency samples associated to a frequency shift of $+\phi_{ql}$. Note that the shifted index, $k+p_{ql}$, seems to lead to out-of-range issues for the $\tilde{x}$ array. One must keep in mind that anti-aliasing conditions are applied to prevent this. This issue, not important at this point, will be properly addressed below, in Eq.~\ref{eq:v2}. After being applied the frequency shift, the data vector $\tilde{x}$ is multiplied by the window derived in Eq.~\ref{eq:dbisquare1} and is Fourier-transformed back in the time domain, as defined by Eq.~\ref{eq:dFTbackward}. In the tiling structure generated in Sec.\ref{sec:algorithm:tiling}, for a given $Q$ plane and frequency row, only $N_\tau(Q_q, \phi_{ql})$ $Q$ transform coefficients must be computed to cover the time chunk $T_c$. Using the time position of tile $(m,l,q)$, we get the simple relation $j=(m+1/2)\frac{N_c}{N_\tau}$. As a result, the discrete $Q$ transform coefficient for tile $(m,l,q)$ becomes
\begin{equation}
  X(m, l, q) = \frac{f_w}{N_c}\sum_{k=0}^{N_c-1}{\tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau}\mathrm{e}^{+2i\pi mk/N_\tau}}.
  \label{eq:dqtransform2}
\end{equation}
The phase shift of $\pi$ is introduced to correct for half a tile to recover the central time of a tile. The bisquare window of Eq.~\ref{eq:dbisquare1} takes non-zero values only over $M_{ql}$ samples. As a result, Eq.~\ref{eq:dqtransform2} can be written as the sum of three terms:
\begin{align}
  X(m, l, q)
  = & \frac{f_w}{N_c} \sum_{k=0}^{(M_{ql}-1)/2}{\tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau} \; \mathrm{e}^{+2i\pi mk/N_\tau}} \\
  + & \frac{f_w}{N_c} \sum_{k=(M_{ql}+1)/2}^{N_c-(M_{ql}-3)/2}{0 \; \mathrm{e}^{+2i\pi mk/N_\tau}} \\
  + & \frac{f_w}{N_c} \sum_{k=N_c-(M_{ql}-1)/2}^{N_c-1}{\tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau} \; \mathrm{e}^{+2i\pi mk/N_\tau}} .
  \label{eq:dqtransform3}
\end{align}
The second term consists of summing $N_c-M_{ql}$ zeros. It is possible to remove $N_c-N_\tau$ zeros in that sum so that $X(m,l,q)$ becomes a sum of $N_\tau$ terms:
\begin{align}
  X(m, l, q)
  = & \frac{f_w}{N_c} \sum_{k=0}^{(M_{ql}-1)/2}{\tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau} \; \mathrm{e}^{+2i\pi mk/N_\tau}} \\
  + & \frac{f_w}{N_c} \sum_{k=(M_{ql}+1)/2}^{N_\tau-(M_{ql}-3)/2}{0 \; \mathrm{e}^{+2i\pi mk/N_\tau}} \\
  - & \frac{f_w}{N_c} \sum_{k=N_\tau-(M_{ql}-1)/2}^{N_\tau-1}{\tilde{x}[k+N_c-N_\tau+p_{ql}]\tilde{w}_{ql}^*[k+N_c-N_\tau]\mathrm{e}^{i\pi k/N_\tau} \; \mathrm{e}^{+2i\pi mk/N_\tau}} .
  \label{eq:dqtransform4}
\end{align}
Note that the index $k$ of the third sum has been shifted to match the end of the second sum: $k-(N_c-N_\tau) \rightarrow k$. This is possible because both $N_c$ and $N_\tau$ are power-of-two values so we have: $\mathrm{e}^{+2i\pi m(k+N_c-N_\tau)/N_\tau} = \mathrm{e}^{+2i\pi mk/N_\tau}$ and $\mathrm{e}^{i\pi (k+N_c-N_\tau)/N_\tau}=-\mathrm{e}^{i\pi k/N_\tau}$. Finally, the sum of Eq.~\ref{eq:dqtransform4} can be recombined into a single sum:
\begin{equation}
  X(m, l, q) = \frac{N_\tau}{N_c} \; \times \; \frac{f_w}{N_\tau} \sum_{k=0}^{N_\tau-1}{\tilde{v}_{ql}[k]\mathrm{e}^{+2i\pi mk/N_\tau}},
  \label{eq:dqtransform5}
\end{equation}
where
\begin{equation}
  \tilde{v}_{ql}[k] =
  \begin{cases}
    \tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau}                     & 0 \le k < (M_{ql}+1)/2 \\
    0                                                                              & (M_{ql}+1)/2 \le k < N_\tau-(M_{ql}-1)/2 \\
    -\tilde{x}[k+N_c-N_\tau+p_{ql}]\tilde{w}_{ql}^*[k+N_c-N_\tau]\mathrm{e}^{i\pi k/N_\tau} & N_\tau-(M_{ql}-1)/2 \le k < N_\tau.
  \end{cases}
  \label{eq:v1}
\end{equation}
This equation shows that a single and less expensive inverse Fourier transform of $\tilde{v}_{ql}$ is sufficient to populate the $N_\tau$ tiles of a frequency row $(q,l)$. As prescribed in Sec.~\ref{sec:algorithm:tiling}, $N_\tau(Q_q, \phi_{ql})$ is rounded up to a power of 2 to offer an optimal Fourier transform.

When the \texttt{Omicron} object is initialized, $N_Q\times N_{\phi}$ Fourier transform plans are created to perform the inverse Fourier transforms for all $Q$ planes and all frequency rows. Care must be taken when populating the $\tilde{v}_{ql}$ array. Indeed, one must reconcile the different size conventions used until this point: $\tilde{v}_{ql}$ is of size $N_\tau $, the whitened data vector, $\tilde{x}$, resulting from a real-to-complex Fourier transform, is of size $N_c/2+1$ (cf. Sec.~\ref{sec:algorithm:whitening}), and the window, $\tilde{w}^*_{ql}$, saved without the zero values, is of size $M_{ql}$ (cf. Eq.~\ref{eq:dbisquare2}). When taking into account these conventions, the array $\tilde{v}_{ql}$ now writes:
\begin{equation}
  \tilde{v}_{ql}[k] =
  \begin{cases}
    \tilde{x}[k+p_{ql}]\tilde{w}_{ql}^*[k]\mathrm{e}^{i\pi k/N_\tau}                     & 0 \le k < (M_{ql}+1)/2 \\
    0                                                        & (M_{ql}+1)/2 \le k < N_\tau-(M_{ql}-1)/2 \\
    -\tilde{x}[\;|N_\tau-k-p_{ql}|\;]\tilde{w}_{ql}^*[k+M_{ql}-N_\tau]\mathrm{e}^{i\pi k/N_\tau} & N_\tau-(M_{ql}-1)/2 \le k < N_\tau.
  \end{cases}
  \label{eq:v2}
\end{equation}
The indexes used in Eq.~\ref{eq:v2} are all consistent with vector sizes. The out-of-range issue described at the beginning of this section no longer exists.

To optimize the processing, the phase shift of $\pi$ is computed a single time, when the window is constructed (see Sec.~\ref{sec:algorithm:window}). The window expression given in Eq.~\ref{eq:dbisquare2} is modified such as
\begin{equation}
  \tilde{w}_{ql}^*[k] =
  \begin{cases}
    W_b \left[1 - \left(\frac{2k}{M_{ql}-1}\right)^2 \right]^2 \mathrm{e}^{i\pi k/N_\tau} & 0\le k < \frac{M_{ql}+1}{2}, \\
    -W_b \left[1 - \left(\frac{2(k-M_{ql})}{M_{ql}-1}\right)^2 \right]^2 \mathrm{e}^{i\pi (k+N_\tau-M_{ql})/N_\tau} & \frac{M_{ql}+1}{2}\le k < M_{ql}.
  \end{cases}
\end{equation}

The $Q$ tansform coefficients are computed by the \texttt{Omicron::Project()} function, for all tiles, $(m,l,q)$, after performing $N_Q\times N_{\phi}(Q,\phi)$ inverse Fourier transforms:
\begin{equation}
  X(m, l, q) = \frac{N_\tau}{N_c} v_{ql}[m].
  \label{eq:qcoeff}
\end{equation}

To test the $Q$ transform implementation, we ran the Omicron algorithm over a pure white noise data set. As explained in Sec.~\ref{sec:method:snr}, we expect an exponential distribution for the $Q$ transform energies $|X|^2$. Figure~\ref{fig:noise_energy_gaus} presents the distribution of the energy coefficients obtained by Omicron. As expected, the distribution mean value is 2.0, the standard deviation is 2.0 and it is well fitted by an exponential.
\begin{figure}
  \center
  \epsfig{width=10cm, file=./figures/noise_energy_gaus.eps}
  \caption{Distribution of energies, $|X|^2$, measured by Omicron when ran over white noise data (blue points). The distribution is fitted by an exponential with a good $\chi^2/ndf$ and the mean value is 2.0, as expected from a white signal (see Sec.~\ref{sec:method:snr}).}
  \label{fig:noise_energy_gaus}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  SNR
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{The signal-to-noise ratio estimate} \label{sec:algorithm:snr}

%An amplitude SNR value is assigned to each tile $(m,l,q)$. It is computed using the estimator in Eq.~\ref{eq:snrestimator}:
%\begin{equation}
%  \hat{\rho}_{qlm} = \sqrt{ |X^{wh}(m,l,q)|^2-\langle |X^{wh}_n(m,l,q)|^2 \rangle}.
%\end{equation}
%In a case of an ideal whitening, $\langle |X^{wh}_n(m,l,q)|^2 \rangle = 2$ and the SNR estimate $\hat{\rho}_{qlm}$ can be trivially derived. However, we know that the whitening procedure described in Sec.~\ref{sec:algorithm:whitening} presents limitations: narrow spectral lines are not sufficiently resolved, the data is assumed to be stationary over a time segment used to estimate the PSD ($T_\mathrm{PSD}$), the data presents many non-Gaussian features\dots As a consequence, the mean value $\langle |X^{wh}_n(m,l,q)|^2 \rangle$ is estimated every time.

%For a given time chunk, the squared magnitude of the $Q$ transform coefficients are averaged over a frequency row $(q,l)$: $\langle |X^{wh}(m,l,q)|^2 \rangle_m$. To have an estimate only for noise, tiles on both edges of the time chunk ($T_o/2$) are not considered because they may suffer from filtering artifacts (see Sec.~\ref{sec:algorithm:conditioning}). Moreover, tiles with $|X^{wh}(m,l,q)|^2 > E_{th}$ are excluded to reject outliers. The threshold value $E_{th}$ is chosen such that the distribution of tile energies below the threshold is dominated by noise events (refer to Fig.~\ref{fig:noise_energy_gaus} to gauge this value). As a consequence, the mean value of the resulting distribution must be corrected by a factor accounting for the fact that the distribution is truncated. Asuming an exponential distribution, the truncated expectation value is
%\begin{align}
%  \langle |X|^2 \rangle_{|X|^2<E_{th}} &= \int_0^{E_{th}}\frac{|X|^2}{\langle |X|^2\rangle}e^{-|X|^2/\langle |X|^2\rangle}d|X|^2 \\
%  &= \langle |X^2|\rangle - e^{\frac{|X|^2}{\langle |X^2|\rangle}} \left(E_{th}+ \langle |X^2|\rangle \right)
%\end{align}

%For the denominator, the expectation value for the noise energy is evaluated using a set of tiles, $(i,l,q)$, $i\in\cal{T}$, representing the local stationary white noise. We consider all the tiles in the same $Q$ plane $q$ and along the same frequency row $l$. The time index $i$ can take any value over the chunk duration, excluding the edges overlapping the surrounding chunks: $i \in [f_wT_o/2; N_\tau(Q_q,\phi_l)-f_wT_o/2[$. Across the chunk frequency row, the data may contain outliers which should not be considered as they contradict the stationary noise hypothesis. To exclude these tiles we use the box-plot prescription from Tukey~\cite{tukey:1977}, illustrated in Fig.~\ref{fig:boxplot}. The $Q$ transform energies, $|X|^2$, are distributed into quartiles. Outliers are rejected if they stand above a threshold given by $|X|^2_{75} + 2\Delta |X|^2$, where $|X|^2_{75}$ is the third quartile and $\Delta |X|^2$ is the interquartile range.
%\begin{figure}
%  \center
%  \epsfig{width=10cm, file=./figures/boxplot.eps}
%  \caption{Box-plot method used to estimate the expectation value of the $Q$ transform energies for a local stationary white noise. For a given chunk of data, the $Q$ transform energies,$|X|^2$, of a frequency row of a $Q$ plane are distributed into quartiles. Outliers are rejected if they lie above a threshold given by $|X|^2_{75} + 2\Delta |X|^2$. Below this value, the distribution is assumed to result from a stationary white noise.}
%  \label{fig:boxplot}
%\end{figure}
%The mean value $\langle |X(i,l,q)|^2 \rangle_{i\in \cal{T}}$ estimated with the box-plot method is biased since a part of the distribution was truncated: $\langle |X_n(m,l,q)|^2 \rangle \neq \langle |X(i,l,q)|^2 \rangle_{i\in \cal{T}}$. However we know that the energy coefficients are exponentially distributed (see Sec.~\ref{sec:method:snr} and Fig.~\ref{fig:boxplot}), it is therefore possible to calculate the bias and correct for it~\cite{Chatterji:2004}:
%\begin{equation}
%  \langle |X_n(m,l,q)|^2 \rangle =  \frac{35}{35-\ln(36)} \langle |X(i,l,q)|^2 \rangle_{i\in \cal{T}}.
%\end{equation}
%Fig.~\ref{fig:noise_energy} shows an example of the outlier rejection procedure. The $Q$ transform energies computed for real non-stationary data are represented in red and present high-energy outliers. The box-plot procedure is applied and coefficients with $|X|^2>7.2$ are rejected. The right-hand plot in Fig.~\ref{fig:noise_energy} shows the remaining distribution which is highly compatible with an exponential distribution (in blue) expected from a stationary noise.
%\begin{figure}
%  \center
%  \epsfig{width=8cm, file=./figures/noise_energy_comp.eps}
%  \epsfig{width=8cm, file=./figures/noise_energy_norm.eps}
%  \caption{Noise energy.as Tiles , 8192 tiles, thr=7.2. }
%  \label{fig:noise_energy}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  TRIGGERS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The triggers} \label{sec:algorithm:triggering}
One of the output products of Omicron is a list of tiles the SNR of which is above a threshold, $\rho_{min}$, defined in the user parameter file: a tile with $\hat{\rho}_{qlm} > \rho_{min}$ is called a trigger. A trigger, associated to tile $(q,l,m)$, is described by a set of 10 parameters:
\begin{enumerate}
  \item the tile central time, $\tau_{qlm}$ defined by Eq.~\ref{eq:tau},
  \item the tile central frequency, $\phi_{ql}$ defined by Eq.~\ref{eq:phi},
  \item the $Q$ plane $Q$ value, $Q_{q}$ defined by Eq.~\ref{eq:q},
  \item an amplitude SNR estimated using Eq.~\ref{eq:snrestimator}: $\hat{\rho}_{qlm} = \sqrt{ |X^{wh}(m,l,q)|^2-2}$,
  \item an amplitude estimated using Eq.~\ref{eq:amplitude}
  \item a phase value is computed following Eq.~\ref{eq:phase}~\footnote{The $\mathrm{atan2}()$ function is actually implemented},
  \item a starting time, $\tau_{qlm} - \Delta \tau_{ql}/2$, given by Eq.~\ref{eq:dtau},
  \item an ending time, $\tau_{qlm} +\Delta \tau_{ql}/2$, given by Eq.~\ref{eq:dtau},
  \item a starting frequency given by the frequency lower edge, $\phi_{min}[\phi_{max}/\phi_{min}]^{l/N_{\phi}(Q_q)}$,
  \item a ending frequency given by the frequency upper edge, $\phi_{min}[\phi_{max}/\phi_{min}]^{(l+1)/N_{\phi}(Q_q)}$.
\end{enumerate}
Technically, triggers are saved in ROOT ntuples called TTree~\cite{Brun:1997pa}. The TTree class is optimized to reduce disk space and enhance access speed. The trigger TTree is saved in a ROOT file for every data chunk. Besides the triggers, the list of processed time segments~\footnote{List of chunks excluding the overlaps.} are saved as well as the Omicron process metadata. In Fig.~\ref{fig:triggerfile}, the trigger file structure is represented.
\begin{figure}
  \center
  \includegraphics[width=5cm]{./figures/triggerfile.png}
  %\epsfig{width=5cm, file=./figures/triggerfile.eps}
  \caption{Structure of a ROOT trigger files. Triggers are saved in a TTree structure as a set of 10 parameters. The list of processed time segments are saved. Finally, metadata, like the Omicron list of parameters, are also saved.}
  \label{fig:triggerfile}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  MAPPING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The time-frequency mapping} \label{sec:algorithm:mapping}
As described in Sec.~\ref{sec:algorithm:tiling}, $Q$ planes are represented by 2-dimensional histograms (see Fig.~\ref{fig:tiling}), where bins are used to represent the time-frequency tiles. These histograms can be filled by the tile parameters such as the SNR, the amplitude or the phase. Hence, the result of the $Q$ transform can be graphically displayed in time-frequency planes; this is called mapping. In addition to individual $Q$ planes, a combined map can be displayed. The combined map is a representation where $Q$ maps are stacked up with the highest SNR tile displayed on the top. The maps for the GW150914 event in the LIGO Hanford detector's data are plotted in Fig.~\ref{fig:gw150914_map}. Plots in the left column show $Q$ planes filled with SNR values and the right column show $Q$ planes filled with amplitude values.

\begin{figure}
  \center
  \epsfig{width=5.7cm, file=./figures/gw150914snr_q0.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_q0.eps} \\
  \epsfig{width=5.7cm, file=./figures/gw150914snr_q1.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_q1.eps} \\
  \epsfig{width=5.7cm, file=./figures/gw150914snr_q2.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_q2.eps} \\
  \epsfig{width=5.7cm, file=./figures/gw150914snr_q3.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_q3.eps} \\
  \epsfig{width=5.7cm, file=./figures/gw150914snr_q4.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_q4.eps} \\
  \epsfig{width=5.7cm, file=./figures/gw150914snr_full.eps}\epsfig{width=5.7cm, file=./figures/gw150914amp_full.eps}
  \caption{Gravitational-wave event GW150914 as detected by Omicron. Time-frequency maps with SNR values are displayed in the left column and maps with amplitude values are displayed in the right column. The first 5 rows show maps for single $Q$ values. The last row presents the combined map.}
  \label{fig:gw150914_map}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  SIGNAL INJECTIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The injection of simulated signals} \label{sec:algorithm:injections}
The Omicron algorithm offers the possibility to add simulated signals in the data and to process the resulting data stream. This can be done in three different ways.

First, simulated data can be read from frames saved in files. To use this feature, the user must provide three parameters in the option file. A frame file list file (\texttt{INJECTION FFL} option) must be given to indicate where the injection data is to be found. If this option is not provided, injection channels are expected to be found in the main FFL file (\texttt{DATA FFL} option). For each main channel (\texttt{DATA CHANNELS} option), an injection channel must be provided with the \texttt{INJECTION CHANNELS} keywords. If the number of main channels and the number of injection channels does not match, the Omicron processing will fail. Finally, it is possible to include a scaling factor with the \texttt{INJECTION FACTORS} keywords, the number of which must also match the number of channels. The final data stream analyzed by Omicron is $x = d + f \times i$, where $d$ and $i$ are the main data vector and the injection vector respectively. The scaling factor is $f$ and is set to 1 if not provided. The data injection is performed right after the main data is loaded, in \texttt{Omicron::LoadData()}, before the conditioning.

Another possibility to inject simulated signals is to use the GWOLLUM injection library. Various waveform models are available and can be added up to the data. Moreover, provided that the detector is recognized~\footnote{In GWOLLUM, LIGO-Virgo detectors are identified based on the channel prefix: H1, H2, L1, V1.}, signals are injected coherently across the network. This means that time offsets are applied and amplitudes are down-weighted by antenna factors. The user must provide injection parameter files defining the desired waveform model as well as the associated parameters (timing, amplitude...). Injection parameter files are ROOT files and they must be generated with the \texttt{InjGen} class~\cite{InjGen_doxygen}. The path to the injection parameter files must be provided with the \texttt{INJECTION FILENAME}. The signal injection is performed right after the main data is loaded, in \texttt{Omicron::LoadData()}, before the conditioning.

Finally, to measure the performance of Omicron, one last class of injections was introduced. Sinusoidal Gaussian waveforms can be injected in the data. The waveform is defined by Eq.~\ref{eq:sg_wave}:
\begin{equation}
  b(t) = Bw(t-\tau_b, \phi_b, Q_b)\cos(2\pi\phi_b t + \theta_b).
  \label{eq:sginj}
\end{equation}
The simulated burst is parameterized by five parameters: an amplitude $B$, a central time $\tau_b$, a frequency $\phi_b$, a quality factor $Q_b$ and a phase term between the signal and the noise $\theta_b$. The Gaussian window is given by Eq.~\ref{eq:gausswindowt}. The user must define intervals in which those parameters will take random values. This is specified by keywords in the user parameter file (\texttt{INJECTION SGTIME}, \texttt{INJECTION SGFREQUENCY}, \texttt{INJECTION SGQ} and \texttt{INJECTION SGAMPLITUDE}). The phase term is not tunable; it takes random values between 0 and $2\pi$. The burst amplitude, frequency and $Q$ values are randomly drawn from a logarithmic distribution. This type of injection is performed a single time per data chunk. Therefore the user must specify a time range taking the chunk center as a reference. For example if a time range $[-0.1; +0.2]$ is specified in the parameter file, the time of the injection $\tau_b$ will be randomly picked bewtween $-0.1$~s and $+0.2$~s with respect to the center of the chunk.

The sinusoidal Gaussian injection feature is activated by setting the option \texttt{INJECTION SG} to 1. Every time a new chunk is loaded with \texttt{Omicron::NewChunk()}, a new waveform is generated using Eq.~\ref{eq:sginj} and with random parameters. The waveform is then added up to the chunk data vector in \texttt{Omicron::LoadData()}. The burst parameters are listed in a text file which is saved at the end of the processing. This file also includes the true SNR value of the burst computed with Eq.~\ref{eq:snr_white}, so it can be compared to the SNR value estimated by Omicron.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  ONLINE APPLICATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The low-latency application} \label{sec:algorithm:online}
Omicron was primarily designed to process data with a low latency. Many structures are initialized in the constructor \texttt{Omicron::Omicron()} so that they are used optimally in the subsequent processing of the data. Moreover, common structures are used as often as possible. For example the tiling structure, which is memory demanding, is common to all channels.

The object-oriented structure of the code offers a flexible analysis-block system which is useful to perform a low-latency processing. The flowchart presented in Fig.~\ref{fig:omicron_flowchart} must be modified to fit the constraints of an online analysis. In particular, FFL files are no longer used as the data are directly streamed in Omicron. The \texttt{Omicron::LoadData()} function takes as an argument any kind of data vector as long as it is compatible with the chunk size and the channel defined in a previous stage.

The \texttt{Omicron} class also offers various and specific functions useful to build an online application. For example, it is possible to buffer triggers before saving them to disk. This features is important if one wants to have a chunk duration as small as possible and write triggers in files with a reasonable size. Functions are also available to interact with the triggers in the buffer. For example, if the trigger rate is found to be too high after the fact, triggers can be removed. Another example is the PSD estimation described in Sec.~\ref{sec:algorithm:whitening}. In an online application, it is possible to control how the whitening is performed: functions are available to interact with the PSD buffer.

Finally, various functions were developed to retrieve information about internal Omicron structures (status, parameters, statistics, errors...). The online application can therefore check the Omicron processing steps and react accordingly.
