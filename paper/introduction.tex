\section{Introduction} \label{sec:introduction}
In 2016, the LIGO and Virgo collaborations announced the first detection of gravitational waves~\cite{Abbott:2016blz}. The signal, detected by the Advanced LIGO interferometers~\cite{Abramovici:1992ah} and labeled GW150914, is associated to a system of two black holes spiraling down and finally merging into a single and final black hole. This event is of very short duration, $\sim200$~ms, and had to be extracted from a very large population of transient noise events, also called glitches, polluting the data of interferometric detectors. Analysis tools have been specifically developed to search for rare gravitational-wave events buried in the detectors' noise. Even if these tools show good intrinsic performance, they are critically limited by the presence of glitches which present features similar to true gravitational-wave signals. As a result, much efforts have been developed to understand, track and veto glitches~\cite{Aasi:2012wd,Aasi:2014mqd,TheLIGOScientific:2016zmo} in order to improve the sensitivity of searches.

Understanding glitches relies on a complete monitoring of the instrument and its environment. For that purpose, thousands of auxiliary data streams are recorded. They include signals from enviromnental alsensors (thermic, acoustic, seismic, magnetic...), from photo-diodes, from actuators, from electronic devices or from feed-back control loops. These auxiliary channels are insensitive to gravitational waves and are used to witness disturbances from noise sources. In particular, transient events must be searched for in thousands of channels data in order to identify correlations with the detector's output data and understand coupling mechanisms leading to glitches. For that purpose, the Omicron algorithm was developed and used to detect transient events in auxiliary data of Advanced gravitational-wave detectors~\cite{Nuttall:2015dqa,TheLIGOScientific:2016zmo}.

Events detected by Omicron are given a set parameters such as timing, frequency or signal strength, defining a trigger. This additional information is useful in the process of understanding the glitch origin. Omicron triggers are processed by many analysis tools and applications~\cite{Isogai:2010zz,Smith:2011an,gspy} to isolate coupling mechanisms or to classify glitches into families. The Omicron algorithm is optimized to process many channels and to produce triggers promptly with limited computing resources. As a result, hundreds of Advanced LIGO and Virgo channels are processed by Omicron in quasi-real time. Therefore, Omicron triggers provides low-latency information about the data quality to the detector operators and to gravitational-wave searches running online.

Omicron is an algorithm designed to search for power excess in data streams using the $Q$ transform~\cite{Brown:1991}. A time-frequency decomposition is used where the data is projected onto a generic basis of complex-valued sinusoidal Gaussian functions. This choice of basis is motivated by several reasons. First, it offers the minimum uncertainty for both time and frequency, offering the best time-frequency characterization of arbitrary events. Then, a multiresolution structure was adopted, using different quality factor values to perform the time-frequency decomposition. As result, different time scales can be resolved. Such a basis is said to be overcomplete (the projection of one basis element onto another one is not 0) allowing for a maximal detection efficiency.

In addition of producing triggers, Omicron includes event display features. For a given event, different data products can be generated and displayed in web pages. It includes time series and noise spectra at the time of the event, or time-frequency maps. Such a feature is widely used by the LIGO and Virgo collaboration to follow-up an event and to better understand noise coupling in play.

The $Q$ transform was first implemented in a LIGO-Virgo search tool called $Q$ pipeline~\cite{Chatterji:2004}, searching for astrophysically unmodeled bursts of gravitational radiation in data from networks of interferometric detectors~\cite{Abbott:2009zi,Abbott:2009up,Abadie:2010mt}. $Q$ pipeline later became Omega~\cite{Rollins:2011} for which improvements were perfomed to process data with low latency and to include a multi-detector coherent techniques. However, neither $Q$ pipeline nor Omega were designed to process hundreds of auxiliary channels required to study coupling in the detectors. Omicron was developed to unite the robustness and parameter estimation accuracy of a gravitational-wave transient search with the computational efficiency required for a near real-time analysis of several hundred channels on available computational resources. Omicron is also used to detect unmodeled gravitational-wave events with low latency. The oLIB search pipeline~\cite{Lynch:2015yin} is processing LIGO and Virgo Omicron online triggers and contributed to the discovery of GW150914~\cite{TheLIGOScientific:2016uux}.

This paper is structured as follows. Sec.~\ref{sec:method} introduces the different concepts used by the Omicron algorithm while Sec.~\ref{sec:algorithm} explains how these concepts are implemented, tested and characterized. In Sec.~\ref{sec:limitations}, we present the known limitations of the tool. Omicron is characterized in Sec.~\ref{sec:characterization}. Finally a conclusion is drawn in Sec.~\ref{sec:conclusion}.

In this paper, we tested all the Omicron analysis steps using real gravitational-wave detectors' data. In particular we used the data surrounding the first detected gravitational-wave event, GW150914~\cite{GW150914data}. In Appx~\ref{appx:parameters}, we provide the Omicron configuration file used to analyze the GW150914 event and to produce all the plots in this paper.




